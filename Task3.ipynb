{"cells":[{"cell_type":"markdown","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8U712fspFXa","outputId":"7fe20354-ff03-4d7f-a233-c78537d85b75"},"source":["importing the necessary libaries"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import cv2\n","from keras.applications.vgg16 import VGG16\n","import tkinter as tk\n","from tkinter import filedialog"]},{"cell_type":"markdown","metadata":{},"source":["model building ,training and testing for sleeping face detection"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 300 images belonging to 2 classes.\n","Epoch 1/5\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.6592 - loss: 0.6731\n","Epoch 2/5\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3s/step - accuracy: 0.8806 - loss: 0.6068\n","Epoch 3/5\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3s/step - accuracy: 0.9431 - loss: 0.5553\n","Epoch 4/5\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - accuracy: 0.9956 - loss: 0.5031\n","Epoch 5/5\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - accuracy: 0.9982 - loss: 0.4602\n","Found 80 images belonging to 2 classes.\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.7547 - loss: 0.5689\n","the test accuracy was found to be: 0.5646839141845703\n"]}],"source":["# Loading the VGGFace model\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# Freezing the base model\n","base_model.trainable = False\n","\n","# Adding custom layers to the model\n","global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n","prediction_layer = tf.keras.layers.Dense(2, activation='sigmoid')\n","\n","model = tf.keras.Sequential([\n","        base_model,\n","        global_average_layer,\n","        prediction_layer\n","])\n","\n","# Fine-tuning the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","\n","# Loading the training data\n","train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n","train_generator = train_datagen.flow_from_directory(r'C:\\Users\\Shivam Sharma\\Documents\\Python Scripts\\task3\\datasets\\sleeping_train', target_size=(224, 224), batch_size=32, class_mode='categorical')\n","\n","# Training the model\n","history = model.fit(train_generator, epochs=5)\n","\n","# Evaluating the model on the test dataset\n","test_generator = train_datagen.flow_from_directory(r'C:\\Users\\Shivam Sharma\\Documents\\Python Scripts\\task3\\datasets\\sleeping_test', target_size=(224, 224), batch_size=32, class_mode='categorical')\n","evaluation = model.evaluate(test_generator)\n","print('the test accuracy was found to be:',evaluation[0])"]},{"cell_type":"markdown","metadata":{},"source":[" model building , training and testing for age prediction of the detected face"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 9479 images belonging to 95 classes.\n","Epoch 1/2\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1140s\u001b[0m 4s/step - accuracy: 0.0209 - loss: 4.5387\n","Epoch 2/2\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1023s\u001b[0m 3s/step - accuracy: 0.0560 - loss: 4.2155\n","Found 2790 images belonging to 95 classes.\n","\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 3s/step - accuracy: 0.0551 - loss: 4.1040\n","the test accuracy was found to be: 4.106809139251709\n"]}],"source":["# Adding custom layers to the model\n","age_prediction_layer = tf.keras.layers.Dense(95, activation='sigmoid')\n","\n","age_model = tf.keras.Sequential([\n","        base_model,\n","        global_average_layer,\n","        age_prediction_layer\n","])\n","\n","# Fine-tuning the model\n","age_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","\n","# Loading the training data\n","train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n","age_train_generator = train_datagen.flow_from_directory(r'C:\\Users\\Shivam Sharma\\Documents\\Python Scripts\\task3\\datasets\\age_train', target_size=(224, 224), batch_size=32, class_mode='categorical')\n","\n","# Training the model\n","age_history = age_model.fit(age_train_generator, epochs=2)\n","\n","# Evaluating the model on the test dataset\n","age_test_generator = train_datagen.flow_from_directory(r'C:\\Users\\Shivam Sharma\\Documents\\Python Scripts\\task3\\datasets\\age_test', target_size=(224, 224), batch_size=32, class_mode='categorical')\n","age_evaluation = age_model.evaluate(age_test_generator)\n","print('the test accuracy was found to be:',age_evaluation[0])"]},{"cell_type":"markdown","metadata":{},"source":["building the necassary function "]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[],"source":["face_cascade = cv2.CascadeClassifier(r'C:\\Users\\Shivam Sharma\\Documents\\Python Scripts\\task3\\haarcascade_frontalface_default (1).xml')\n","#to extract class name from prediction of the model\n","def extract_class_name(predictions,train_generator):\n","      # Geting the class label with the highest predicted probability\n","      class_label = np.argmax(predictions)\n","\n","      # Maping the integer label to the corresponding class name\n","      class_names = train_generator.class_indices\n","      class_name = [k for k, v in class_names.items() if v == class_label][0]\n","      return class_name\n","\n","#image_detection\n","def is_image(filename):\n","    #Returns True if the file at the given path is an image, and False otherwise\n","    try:\n","        img = cv2.imread(filename)\n","        if img is not None:\n","            return True,img\n","        else:\n","            return False,None\n","    except cv2.error:\n","        return False,None\n","\n","#vedio_analysis\n","def vedio_detect_face(vedio_url):\n","    # Opening the video source (either a webcam or a video file)\n","    cap = cv2.VideoCapture(vedio_url)\n","    ved_face=[]\n","    frames=[]\n","    # Processing each frame of the video\n","    while True:\n","        # Reading the next frame of the video\n","        ret, frame = cap.read()\n","\n","        # Checking if the frame was read successfully\n","        if not ret:\n","           break\n","        frames.append(frame)\n","\n","        # Preprocessing steps\n","        # 1. Resizing\n","        frame = cv2.resize(frame, (640, 480))\n","\n","        # 2. Gray scaling\n","        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","        # 3. Smoothing\n","        gray = cv2.GaussianBlur(gray, (7, 7), 0)\n","\n","        # 4. Histogram equalization\n","        gray = cv2.equalizeHist(gray)\n","\n","        # Detection of faces in the grayscale frame\n","        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n","        ved_face.append(faces)\n","    return ved_face,frames\n","\n","\n","\n","def pred_model(faces,v,img):\n","    global new_filename,window,class_name,frames,i,num_sp,age\n","    #cropping the faces from the images\n","    for f_ace in faces:\n","      x, y, w, h = f_ace\n","      face = img[:, y:y+h, x:x+w]\n","      predictions = model.predict(face)\n","      #extracting the name of the class\n","      class_name = extract_class_name(predictions,train_generator)\n","      if class_name == 'sleeping_person':\n","        num_sp+=1\n","        #age prediction of the person\n","        age_prediction = age_model.predict(face)\n","        #extracting the name of the class\n","        age_class_name = extract_class_name(age_prediction,age_train_generator)\n","        age.append(age_class_name)\n","    if v== 0:\n","       if num_sp == 0:\n","         message = tk.Message(window, text=f\"image_url: {new_filename} \\n not found any person sleeping in car\")\n","         message.pack()\n","       else:\n","          message = tk.Message(window, text=f\"image_url: {new_filename} \\n found person sleeping in car \\n the number of person sleeping are {num_sp} \\n the age of the person found sleeping in car are listed below:{age}\")\n","          message.pack()\n","       return\n","    else:\n","       return num_sp,age    "]},{"cell_type":"markdown","metadata":{},"source":["defining the main function"]},{"cell_type":"code","execution_count":131,"metadata":{},"outputs":[],"source":["def main():\n","    global faces,ved_face,new_filename,frames,i,num_sp,age\n","    is_img,img = is_image(new_filename)\n","    # initialising the vairable\n","    age=()#to store the ages of the person sleeping\n","    num_sp=0\n","    if (is_img):\n","        # Preprocessing the image\n","        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","        faces =face_cascade.detectMultiScale(gray)\n","        v=0\n","        pred_model(faces,v,img)\n","    else:\n","        ved_faces,frames=vedio_detect_face(new_filename)\n","        v=1\n","        i=0\n","        for frame in frames:\n","           num_sp,age=pred_model(ved_faces[i],v,frame)\n","           i+=1\n","        if num_sp==0:\n","           message = tk.Message(window, text=f\"vedio_url: {new_filename} \\n not found any person sleeping in car\")\n","           message.pack()\n","        else:\n","            message = tk.Message(window, text=f\"vedio_url: {new_filename} \\n found person sleeping in car \\n the number of person sleeping are {num_sp} \\n the age of the person found sleeping in car are listed below:{age}\")\n","            message.pack() "]},{"cell_type":"markdown","metadata":{},"source":["creating window for user interface"]},{"cell_type":"code","execution_count":126,"metadata":{},"outputs":[{"data":{"text/plain":["''"]},"execution_count":126,"metadata":{},"output_type":"execute_result"}],"source":["window = tk.Tk()\n","window.title(\"image classification of a person in vehicle\")\n","window.geometry(\"500x500\")"]},{"cell_type":"markdown","metadata":{},"source":["building button for file explorer"]},{"cell_type":"code","execution_count":127,"metadata":{},"outputs":[],"source":["\n","label_file_explorer = tk.Label(window, text=\"\")\n","label_file_explorer.pack()"]},{"cell_type":"markdown","metadata":{},"source":["function for browsing the files"]},{"cell_type":"code","execution_count":128,"metadata":{},"outputs":[],"source":["def browseFiles():\n","    global new_filename,filename\n","    filename =''\n","    filename = filedialog.askopenfilename(initialdir=\"/\", title=\"Select a file\",filetypes=((\"Image files\", \"*.png;*.jpg;*.jpeg;*.bmp;*.gif\"),\n","                                                 (\"Video files\", \"*.mp4;*.avi;*.mov;*.mkv;*.flv\"), (\"All files\", \"*.*\")))\n","    label_file_explorer.configure(text=\"File Opened: \" + filename)\n","    new_filename =filename \n","    main()"]},{"cell_type":"markdown","metadata":{},"source":["building upload button"]},{"cell_type":"code","execution_count":129,"metadata":{},"outputs":[],"source":["label_upload = tk.Label(window, text=\"Upload a image or vedio file:\")\n","label_upload.pack()\n","\n","button_upload = tk.Button(window, text=\"Browse\", command=browseFiles)\n","button_upload.pack()\n","window.mainloop()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNBlPZ+XWoM5x2pP+nZS/M9","mount_file_id":"1afho7Bky3rMPTHbCWyiyLIyhH-eHWJGH","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
